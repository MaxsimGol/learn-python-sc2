This section provides a practical, code-oriented example of how to implement a curriculum. We will design a simple, three-stage program to teach our `MicroBot` agent how to handle progressively more difficult combat scenarios, starting with the foundational 1v1 kiting skill.

#### **Curriculum Specification**

A formal training plan requires defining the stages, the skill taught at each stage, and the criteria for advancing to the next.

| Stage | Task Name | Scenario | Primary Skill Learned | Graduation Criterion |
| :--- | :--- | :--- | :--- | :--- |
| **1** | Kiting Fundamentals | 1 Marine vs. 1 Zergling | The core mechanic of kiting: move during weapon cooldown. | > 95% win rate vs. built-in AI. |
| **2** | Target Prioritization | 2 Marines vs. 1 Zergling | How to focus fire on a single target with multiple units. | > 98% win rate vs. built-in AI. |
| **3** | Group Engagement | 2 Marines vs. 2 Zerglings | How to manage multiple threats and maintain group cohesion. | > 90% win rate vs. built-in AI. |

---

#### **Step 1- Parameterize the `gymnasium` Environment**

The first step is to modify our `MicroEnv` so that a single class can create any of the scenarios defined in our curriculum. This is achieved by adding parameters to its constructor.

**Revised `micro_bot.py` (Key Modifications):**
```python
# In micro_bot.py

class MicroBot(BotAI):
    # The BotAI class now accepts the scenario configuration as arguments
    def __init__(self, num_marines: int, num_zerglings: int, **kwargs):
        super().__init__(**kwargs)
        self.num_marines = num_marines
        self.num_zerglings = num_zerglings
        # ... rest of __init__ ...

    async def on_start(self):
        # The on_start method uses these parameters to create the correct scenario
        p = self.start_location
        await self._client.debug_create_unit([[UnitTypeId.MARINE, self.num_marines, p, 1]])
        await self._client.debug_create_unit([[UnitTypeId.ZERGLING, self.num_zerglings, p.towards(self.enemy_start_locations[0], 8), 2]])
        await self._client.debug_kill_unit(self.workers)

class MicroEnv(SC2GymEnv):
    # The GymEnv now accepts the same parameters to pass them on to the bot
    def __init__(self, num_marines: int = 1, num_zerglings: int = 1):
        
        # This is a critical step: Since the BotAI class needs arguments,
        # we must wrap its constructor in a lambda that our SC2GymEnv can call.
        # This passes the correct arguments when the bot is instantiated
        # inside the separate game process.
        bot_constructor = lambda **kwargs: MicroBot(
            num_marines=num_marines,
            num_zerglings=num_zerglings,
            **kwargs
        )
        
        super().__init__(bot_class=bot_constructor, map_name="AcropolisLE")
        # ... rest of __init__ ...
```

---

#### **Step 2- The Automated Training Script (Pseudocode)**

With a configurable environment, we can now write a training manager script that automates the curriculum. This script is responsible for creating the environment for each stage, training the agent, evaluating its performance, and loading its learned policy into the next stage.

The following pseudocode outlines the required logic.

**`curriculum_trainer.py` (Pseudocode Logic):**
```python
from sb3_contrib import MaskablePPO
from micro_bot import MicroEnv
from evaluation import evaluate_agent # Assume a helper function for evaluation

# --- Define the Curriculum Stages ---
curriculum = [
    {"name": "1v1", "marines": 1, "zerglings": 1, "win_rate_goal": 0.95, "model_save_path": "model_stage1.zip"},
    {"name": "2v1", "marines": 2, "zerglings": 1, "win_rate_goal": 0.98, "model_save_path": "model_stage2.zip"},
    {"name": "2v2", "marines": 2, "zerglings": 2, "win_rate_goal": 0.90, "model_save_path": "final_micro_model.zip"},
]

def run_training_curriculum():
    last_model_path = None
    
    for stage in curriculum:
        print(f"--- Starting Curriculum Stage: {stage['name']} ---")
        
        # 1. Create the environment for the current stage
        env = MicroEnv(num_marines=stage["marines"], num_zerglings=stage["zerglings"])
        
        # 2. Load the model from the previous stage, or create a new one for the first stage
        if last_model_path:
            model = MaskablePPO.load(last_model_path, env=env)
            print(f"Loaded model from {last_model_path}")
        else:
            model = MaskablePPO("MlpPolicy", env, verbose=1)
            print("Creating new model for the first stage.")

        # 3. Train the model until it meets the graduation criterion
        while evaluate_agent(model, env) < stage["win_rate_goal"]:
            model.learn(total_timesteps=25_000) # Train for a fixed number of steps per loop
            
        # 4. Save the new model and prepare for the next stage
        model.save(stage["model_save_path"])
        last_model_path = stage["model_save_path"]
        print(f"--- Stage {stage['name']} Complete. Model saved to {last_model_path} ---")
        env.close()

if __name__ == '__main__':
    run_training_curriculum()
```
This structured approach provides a clear and powerful method for tackling complex RL problems. By building upon previously learned skills, the agent can achieve a level of performance that would be difficult or impossible to reach with a single, monolithic training run.