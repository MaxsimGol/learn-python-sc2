"use strict";(self.webpackChunkmy_framework_docs=self.webpackChunkmy_framework_docs||[]).push([[6926],{3802:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.2 - Example - A Curriculum for the Micro Bot","title":"10.2 - Example - A Curriculum for the Micro Bot","description":"Let\'s apply the theory of Curriculum Learning to a practical example. We will design a simple, three-stage curriculum to teach our MicroBot agent how to handle progressively more complex combat scenarios.","source":"@site/docs/Part 5 - Reinforcement Learning/2 - Advanced RL and Next Steps/04-Chapter 10 - Improving Your Agent with Curriculum Learning/10.2 - Example - A Curriculum for the Micro Bot.md","sourceDirName":"Part 5 - Reinforcement Learning/2 - Advanced RL and Next Steps/04-Chapter 10 - Improving Your Agent with Curriculum Learning","slug":"/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.2 - Example - A Curriculum for the Micro Bot","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.2 - Example - A Curriculum for the Micro Bot","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"10.1 - The Concept - From Simple to Complex Tasks","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.1 - The Concept - From Simple to Complex Tasks"},"next":{"title":"11.1 - Summary of Your RL Journey","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.1 - Summary of Your RL Journey"}}');var i=r(4848),a=r(8453);const s={},o=void 0,l={},c=[{value:"<strong>Curriculum Specification</strong>",id:"curriculum-specification",level:4},{value:"<strong>Step 1- Parameterize the Bot and Environment</strong>",id:"step-1--parameterize-the-bot-and-environment",level:4},{value:"<strong>Step 2- Create a Curriculum Training Manager</strong>",id:"step-2--create-a-curriculum-training-manager",level:4}];function m(e){const n={code:"code",h4:"h4",hr:"hr",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["Let's apply the theory of Curriculum Learning to a practical example. We will design a simple, three-stage curriculum to teach our ",(0,i.jsx)(n.code,{children:"MicroBot"})," agent how to handle progressively more complex combat scenarios."]}),"\n",(0,i.jsx)(n.p,{children:"Our goal is to start with the foundational 1v1 kiting skill and build up to managing a small group engagement."}),"\n",(0,i.jsx)(n.h4,{id:"curriculum-specification",children:(0,i.jsx)(n.strong,{children:"Curriculum Specification"})}),"\n",(0,i.jsx)(n.p,{children:"This table defines our staged learning plan."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Stage"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Task Name"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Scenario"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Skill Being Taught"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Graduation Criterion"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"1"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Kiting Fundamentals"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"1 Marine vs. 1 Zergling"}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"The core mechanic of kiting: move during weapon cooldown."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:">95% win rate."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"2"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Target Prioritization"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"2 Marines vs. 1 Zergling"}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"How to focus fire on a single target with multiple units."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:">98% win rate."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"3"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Group Cohesion"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"2 Marines vs. 2 Zerglings"}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"How to manage multiple threats and maintain positioning as a group."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:">90% win rate."})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h4,{id:"step-1--parameterize-the-bot-and-environment",children:(0,i.jsx)(n.strong,{children:"Step 1- Parameterize the Bot and Environment"})}),"\n",(0,i.jsxs)(n.p,{children:["First, we must modify our bot so that it can be configured for each stage of the curriculum. We will add parameters to its ",(0,i.jsx)(n.code,{children:"__init__"})," method to control the number of units spawned. The environment will then pass these parameters during the bot's instantiation."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsxs)(n.strong,{children:["Updated ",(0,i.jsx)(n.code,{children:"micro_bot.py"})," (Relevant parts):"]})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# in micro_bot.py\r\nimport gymnasium as gym\r\nfrom sc2.bot_ai import BotAI\r\nfrom sc2.ids.unit_typeid import UnitTypeId\r\n\r\n# A simple, custom gym-like environment is now common\r\n# as SC2GymEnv is no longer the standard.\r\n# This is a simplified representation for the example.\r\nclass MicroEnv(gym.Env):\r\n    def __init__(self, map_name="AcropolisLE", num_marines: int = 1, num_zerglings: int = 1):\r\n        self.map_name = map_name\r\n        self.num_marines = num_marines\r\n        self.num_zerglings = num_zerglings\r\n        # Define action and observation spaces appropriate for your task\r\n        # This is highly dependent on the specific implementation of the bot\'s actions/observations\r\n        self.action_space = gym.spaces.Discrete(4) # Placeholder\r\n        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(10,)) # Placeholder\r\n\r\n    # The environment needs methods like step, reset, render, close\r\n    # which would contain the game logic. For this example, we focus on the setup.\r\n\r\n    def get_bot(self):\r\n        """Returns an instance of the bot with the configured parameters."""\r\n        return MicroBot(num_marines=self.num_marines, num_zerglings=self.num_zerglings)\r\n\r\n\r\nclass MicroBot(BotAI):\r\n    # __init__ no longer takes action_queue and obs_queue\r\n    def __init__(self, num_marines: int, num_zerglings: int):\r\n        super().__init__()\r\n        self.num_marines = num_marines\r\n        self.num_zerglings = num_zerglings\r\n        # ... rest of __init__ ...\r\n\r\n    async def on_start(self):\r\n        """Spawns units based on the parameters."""\r\n        p = self.start_location\r\n        # Use the parameters to control the number of units created\r\n        await self._client.debug_create_unit([[UnitTypeId.MARINE, self.num_marines, p, 1]])\r\n        await self._client.debug_create_unit([[UnitTypeId.ZERGLING, self.num_zerglings, p.towards(self.enemy_start_locations[0], 8), 2]])\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h4,{id:"step-2--create-a-curriculum-training-manager",children:(0,i.jsx)(n.strong,{children:"Step 2- Create a Curriculum Training Manager"})}),"\n",(0,i.jsx)(n.p,{children:"Next, we need a script that manages the stage-by-stage training process. This script will load the model from the previous stage, create the new, harder environment, and continue training."}),"\n",(0,i.jsxs)(n.p,{children:["The following script, ",(0,i.jsx)(n.code,{children:"training_manager.py"}),", implements the logic required to automate the curriculum."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"training_manager.py"})," (Implementation):"]})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\nfrom stable_baselines3 import PPO\r\nfrom stable_baselines3.common.vec_env import SubprocVecEnv\r\nfrom stable_baselines3.common.env_util import make_vec_env\r\nfrom micro_bot import MicroEnv # Assuming MicroEnv is a gym.Env compatible wrapper\r\n\r\n# A placeholder function for evaluation. In a real scenario, this would\r\n# run several episodes without learning and calculate the win rate.\r\ndef evaluate_win_rate(model, env, num_episodes=100) -> float:\r\n    """\r\n    Evaluates the win rate of the model over a number of episodes.\r\n    NOTE: This is a placeholder. A real implementation would need to\r\n    run the simulation and track wins vs. losses.\r\n    """\r\n    # Placeholder logic: return a dummy value that increases over time\r\n    # to allow the curriculum to proceed.\r\n    # In a real implementation, you would run episodes and calculate true win rate.\r\n    print("Evaluating model... (using placeholder logic)")\r\n    if not hasattr(evaluate_win_rate, "win_rate"):\r\n        evaluate_win_rate.win_rate = 0.80 # Initial dummy win rate\r\n    else:\r\n        evaluate_win_rate.win_rate += 0.08 # Increase dummy win rate each time it\'s called\r\n    \r\n    print(f"Current win rate: {evaluate_win_rate.win_rate:.2f}")\r\n    return min(evaluate_win_rate.win_rate, 1.0)\r\n\r\n\r\ndef run_curriculum(if_multiprocess:bool = False):\r\n    # --- STAGE 1: Kiting Fundamentals ---\r\n    print("--- Starting Stage 1: 1v1 ---")\r\n    # Using make_vec_env to create a vectorized environment\r\n    env_stage1 = make_vec_env(MicroEnv, n_envs=4 if if_multiprocess else 1,\r\n                              vec_env_cls=SubprocVecEnv if if_multiprocess else None,\r\n                              env_kwargs={\'num_marines\': 1, \'num_zerglings\': 1})\r\n                              \r\n    model = PPO("MlpPolicy", env_stage1, verbose=1)\r\n    \r\n    # Train until the graduation criterion is met\r\n    while evaluate_win_rate(model, env_stage1) < 0.95:\r\n        model.learn(total_timesteps=20_000)\r\n    \r\n    model.save("model_stage1")\r\n    print("--- Stage 1 Complete. ---")\r\n    env_stage1.close()\r\n\r\n    # --- STAGE 2: Target Prioritization ---\r\n    print("--- Starting Stage 2: 2v1 ---")\r\n    env_stage2 = make_vec_env(MicroEnv, n_envs=4 if if_multiprocess else 1,\r\n                              vec_env_cls=SubprocVecEnv if if_multiprocess else None,\r\n                              env_kwargs={\'num_marines\': 2, \'num_zerglings\': 1})\r\n    \r\n    # Load the model and set the new environment\r\n    model = PPO.load("model_stage1")\r\n    model.set_env(env_stage2)\r\n\r\n    while evaluate_win_rate(model, env_stage2) < 0.98:\r\n        model.learn(total_timesteps=20_000)\r\n\r\n    model.save("model_stage2")\r\n    print("--- Stage 2 Complete. ---")\r\n    env_stage2.close()\r\n\r\n    # --- STAGE 3: Group Cohesion ---\r\n    print("--- Starting Stage 3: 2v2 ---")\r\n    env_stage3 = make_vec_env(MicroEnv, n_envs=4 if if_multiprocess else 1,\r\n                              vec_env_cls=SubprocVecEnv if if_multiprocess else None,\r\n                              env_kwargs={\'num_marines\': 2, \'num_zerglings\': 2})\r\n\r\n    model = PPO.load("model_stage2")\r\n    model.set_env(env_stage3)\r\n\r\n    while evaluate_win_rate(model, env_stage3) < 0.90:\r\n        model.learn(total_timesteps=20_000)\r\n        \r\n    model.save("final_micro_model")\r\n    print("--- Curriculum Complete! Final model saved. ---")\r\n    env_stage3.close()\r\n\r\nif __name__ == \'__main__\':\r\n    # Set to True if you have configured your system for multiprocessing\r\n    # e.g. by wrapping the script entry point in if __name__ == \'__main__\':\r\n    run_curriculum(if_multiprocess=True)\r\n\n'})}),"\n",(0,i.jsx)(n.p,{children:"This structured, staged approach provides a clear path for teaching a bot complex behaviors. By mastering simple skills first, the agent is much better equipped to find effective policies for the final, more difficult tasks."})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>o});var t=r(6540);const i={},a=t.createContext(i);function s(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);