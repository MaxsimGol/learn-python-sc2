"use strict";(self.webpackChunkmy_framework_docs=self.webpackChunkmy_framework_docs||[]).push([[7282],{8453:(e,t,n)=>{n.d(t,{R:()=>l,x:()=>o});var s=n(6540);const i={},r=s.createContext(i);function l(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(r.Provider,{value:t},e.children)}},9948:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space","title":"4.2 - Design - Expanding the State and Action Space","description":"To graduate our agent from a single-purpose actor to a decision-maker, we must evolve its environment. This involves expanding its \\"senses\\" (the observation space) and its \\"abilities\\" (the action space) to provide the necessary tools for learning the more complex task of balancing economic priorities.","source":"@site/docs/Part 5 - Reinforcement Learning/1 - Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space.md","sourceDirName":"Part 5 - Reinforcement Learning/1 - Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot","slug":"/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"4.1 - Goal - Learning an Economic Trade-off","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off"},"next":{"title":"4.3 - Code - The Macro Bot Environment","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.3 - Code - The Macro Bot Environment"}}');var i=n(4848),r=n(8453);const l={},o=void 0,c={},d=[{value:"<strong>Agent Requirements Analysis</strong>",id:"agent-requirements-analysis",level:4},{value:"<strong>1. Observation Space Evolution</strong>",id:"1-observation-space-evolution",level:4},{value:"<strong>2. Action Space Evolution</strong>",id:"2-action-space-evolution",level:4}];function a(e){const t={code:"code",h4:"h4",hr:"hr",input:"input",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:'To graduate our agent from a single-purpose actor to a decision-maker, we must evolve its environment. This involves expanding its "senses" (the observation space) and its "abilities" (the action space) to provide the necessary tools for learning the more complex task of balancing economic priorities.'}),"\n",(0,i.jsxs)(t.p,{children:["This document details the design changes from the ",(0,i.jsx)(t.code,{children:"WorkerEnv"})," to the new ",(0,i.jsx)(t.code,{children:"MacroEnv"}),"."]}),"\n",(0,i.jsx)(t.h4,{id:"agent-requirements-analysis",children:(0,i.jsx)(t.strong,{children:"Agent Requirements Analysis"})}),"\n",(0,i.jsx)(t.p,{children:"The new task requires the agent to:"}),"\n",(0,i.jsxs)(t.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(t.li,{className:"task-list-item",children:[(0,i.jsx)(t.input,{type:"checkbox",checked:!0,disabled:!0})," ","Sense when its supply capacity is becoming a limiting factor."]}),"\n",(0,i.jsxs)(t.li,{className:"task-list-item",children:[(0,i.jsx)(t.input,{type:"checkbox",checked:!0,disabled:!0})," ","Possess the ability to increase that supply capacity."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"This mandates a direct evolution of our environment's API."}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsx)(t.h4,{id:"1-observation-space-evolution",children:(0,i.jsx)(t.strong,{children:"1. Observation Space Evolution"})}),"\n",(0,i.jsxs)(t.p,{children:["The agent needs a more complete picture of its supply situation than just ",(0,i.jsx)(t.code,{children:"supply_left"}),". We will provide the raw components of supply to allow the agent to learn the relationship itself."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:"Design Comparison:"})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsxs)(t.strong,{children:[(0,i.jsx)(t.code,{children:"WorkerEnv"})," Observation Space - ",(0,i.jsx)(t.code,{children:"Box(3,)"})]})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Index"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Feature"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"0"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Minerals"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"1"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Worker Count"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"2"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Supply Left"})]})]})]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsxs)(t.strong,{children:[(0,i.jsx)(t.code,{children:"MacroEnv"})," Observation Space - ",(0,i.jsx)(t.code,{children:"Box(4,)"})]})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Index"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Feature"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Rationale for Change"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"0"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Minerals"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"(Unchanged) Required for affordability checks."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"1"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Worker Count"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"(Unchanged) Required as a progress metric."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"2"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.strong,{children:(0,i.jsx)(t.code,{children:"supply_used"})})}),(0,i.jsxs)(t.td,{style:{textAlign:"left"},children:[(0,i.jsx)(t.strong,{children:"(New)"}),' Provides the "demand" side of the supply equation.']})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"3"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.strong,{children:(0,i.jsx)(t.code,{children:"supply_cap"})})}),(0,i.jsxs)(t.td,{style:{textAlign:"left"},children:[(0,i.jsx)(t.strong,{children:"(New)"}),' Provides the "supply" side of the equation.']})]})]})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Rationale:"})," Providing ",(0,i.jsx)(t.code,{children:"supply_used"})," and ",(0,i.jsx)(t.code,{children:"supply_cap"}),' separately is a more robust design. It gives the agent the raw data and allows the neural network to learn the concept of "supply pressure" on its own, which can lead to a more nuanced and effective policy.']}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsx)(t.h4,{id:"2-action-space-evolution",children:(0,i.jsx)(t.strong,{children:"2. Action Space Evolution"})}),"\n",(0,i.jsx)(t.p,{children:"To meet the new requirements, the agent must be given the ability to build a supply structure."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:"Design Comparison:"})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsxs)(t.strong,{children:[(0,i.jsx)(t.code,{children:"WorkerEnv"})," Action Space - ",(0,i.jsx)(t.code,{children:"Discrete(2)"})]})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Action"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Meaning"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"0"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Do Nothing"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"1"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Build Worker"})]})]})]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsxs)(t.strong,{children:[(0,i.jsx)(t.code,{children:"MacroEnv"})," Action Space - ",(0,i.jsx)(t.code,{children:"Discrete(3)"})]})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Action"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Meaning"}),(0,i.jsx)(t.th,{style:{textAlign:"left"},children:"Rationale for Change"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"0"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Do Nothing"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"(Unchanged) A passive choice is always required."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"1"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"Build Worker"}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:"(Unchanged) The primary economic action."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.code,{children:"2"})}),(0,i.jsx)(t.td,{style:{textAlign:"left"},children:(0,i.jsx)(t.strong,{children:"Build Supply"})}),(0,i.jsxs)(t.td,{style:{textAlign:"left"},children:[(0,i.jsx)(t.strong,{children:"(New)"})," Directly provides the agent with the tool needed to solve the new problem."]})]})]})]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"These modifications transform the environment from a simple, single-goal task to a more dynamic system where the agent must learn to prioritize actions based on a richer set of inputs."})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}}}]);