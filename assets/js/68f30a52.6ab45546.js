"use strict";(self.webpackChunkmy_framework_docs=self.webpackChunkmy_framework_docs||[]).push([[596],{6377:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off","title":"4.1 - Goal - Learning an Economic Trade-off","description":"Having successfully trained an agent on a single task, we now introduce a core element of strategy games: decision-making under constraints. Our second agent will learn to manage the fundamental economic trade-off between building more workers (increasing income) and building more supply (increasing capacity).","source":"@site/docs/Part 5 - Reinforcement Learning/1 - Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off.md","sourceDirName":"Part 5 - Reinforcement Learning/1 - Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot","slug":"/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"3.3 - Code - The Worker Bot Environment","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.3 - Code - The Worker Bot Environment"},"next":{"title":"4.2 - Design - Expanding the State and Action Space","permalink":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space"}}');var s=t(4848),r=t(8453);const l={},o=void 0,c={},a=[{value:"<strong>The Conceptual Challenge- Balancing Competing Goods</strong>",id:"the-conceptual-challenge--balancing-competing-goods",level:4},{value:"<strong>Success Criteria</strong>",id:"success-criteria",level:4},{value:"<strong>Environment Design</strong>",id:"environment-design",level:4}];function d(e){const n={code:"code",h4:"h4",hr:"hr",input:"input",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.p,{children:["Having successfully trained an agent on a single task, we now introduce a core element of strategy games: ",(0,s.jsx)(n.strong,{children:"decision-making under constraints"}),". Our second agent will learn to manage the fundamental economic trade-off between building more ",(0,s.jsx)(n.strong,{children:"workers"})," (increasing income) and building more ",(0,s.jsx)(n.strong,{children:"supply"})," (increasing capacity)."]}),"\n",(0,s.jsx)(n.p,{children:"This task is designed to teach the agent to prioritize actions based on a dynamic game state, moving beyond a single, repetitive goal."}),"\n",(0,s.jsx)(n.h4,{id:"the-conceptual-challenge--balancing-competing-goods",children:(0,s.jsx)(n.strong,{children:"The Conceptual Challenge- Balancing Competing Goods"})}),"\n",(0,s.jsx)(n.p,{children:'The agent must learn that both actions are "good" but that one is often more critical than the other depending on the situation.'}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"+------------------------+      +-----------------------------+\r\n|   Action 1: Build SCV  |      |  Action 2: Build Depot      |\r\n+------------------------+      +-----------------------------+\r\n|        PROS:           |      |          PROS:              |\r\n|  + Increases Income    |      |  + Unlocks Army Growth      |\r\n|        CONS:           |      |          CONS:              |\r\n|  - Consumes Supply     |      |  - Does not increase Income |\r\n|                        |      |                             |\r\n+-----------^------------+      +-------------^---------------+\r\n            |                                |\r\n            |      WHICH ONE IS BETTER       |\r\n            |          RIGHT NOW?            |\r\n            +--------------------------------+\r\n                          |\r\n            +-------------v---------------+\r\n            |      The Agent's Policy     |\r\n            +-----------------------------+\n"})}),"\n",(0,s.jsx)(n.h4,{id:"success-criteria",children:(0,s.jsx)(n.strong,{children:"Success Criteria"})}),"\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","The agent must learn to continuously produce workers."]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","The agent must learn to proactively build Supply Depots to avoid being supply-blocked."]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","The agent must learn to prioritize depot construction when ",(0,s.jsx)(n.code,{children:"supply_left"})," is low, even if it has enough minerals to build a worker."]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","The episode must terminate successfully upon reaching a target of 30 workers."]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h4,{id:"environment-design",children:(0,s.jsx)(n.strong,{children:"Environment Design"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"1. Observation Space Specification"})}),"\n",(0,s.jsx)(n.p,{children:"To make an informed decision, the agent now needs full visibility into the supply situation."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Gymnasium Type:"})," ",(0,s.jsx)(n.code,{children:"gymnasium.spaces.Box"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Shape:"})," ",(0,s.jsx)(n.code,{children:"(4,)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Type:"})," ",(0,s.jsx)(n.code,{children:"numpy.float32"})]}),"\n"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Index"}),(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Source Feature"}),(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Normalization"}),(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Purpose"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"0"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"self.minerals"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"1000.0"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:'"Can I afford my chosen action?"'})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"1"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"self.workers.amount"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"50.0"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:'"How is my economic progress?"'})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"2"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"self.supply_used"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"200.0"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:'"How much pressure is on my supply?"'})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"3"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"self.supply_cap"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"200.0"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:'"What is my current supply limit?"'})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"2. Action Space Specification"})}),"\n",(0,s.jsx)(n.p,{children:"The action space is expanded to allow for the new building choice."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Gymnasium Type:"})," ",(0,s.jsx)(n.code,{children:"gymnasium.spaces.Discrete"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Size:"})," ",(0,s.jsx)(n.code,{children:"3"})]}),"\n"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Action Value"}),(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Agent's Intent"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"0"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Do Nothing"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"1"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Build Worker (SCV)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"2"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Build Supply (Supply Depot)"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"3. Reward Function Specification"})}),"\n",(0,s.jsx)(n.p,{children:"The reward function is designed to heavily punish the primary failure state (getting supply-blocked) while lightly encouraging all productive actions."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Pseudocode Logic:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"function get_reward(action, game_state, last_supply_left):\r\n  reward = 0\r\n\r\n  # Event-Based Penalty for a critical failure\r\n  if game_state.supply_left == 0 and last_supply_left > 0:\r\n    reward -= 10\r\n\r\n  # Sparse Rewards for productive actions\r\n  if action == 1 and successfully_trained_worker:\r\n    reward += 1\r\n  elif action == 2 and successfully_built_depot:\r\n    reward += 2 // Slightly higher to incentivize this crucial task\r\n\r\n  return reward\n"})}),"\n",(0,s.jsx)(n.p,{children:"This design forces the agent to develop a more sophisticated policy. It cannot simply learn to always build workers; it must learn to pay attention to its supply and act preemptively to avoid the large penalty."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>o});var i=t(6540);const s={},r=i.createContext(s);function l(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);