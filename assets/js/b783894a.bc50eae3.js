"use strict";(self.webpackChunkmy_framework_docs=self.webpackChunkmy_framework_docs||[]).push([[213],{4410:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Part 1 - Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Chapter 1 - Introduction","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"1.1 - What is python-sc2","href":"/learn-python-sc2/docs/Part 1 - Getting Started/Chapter 1 - Introduction/1.1 - What is python-sc2","docId":"Part 1 - Getting Started/Chapter 1 - Introduction/1.1 - What is python-sc2","unlisted":false},{"type":"link","label":"1.2 - Why Use the BurnySc2 Fork","href":"/learn-python-sc2/docs/Part 1 - Getting Started/Chapter 1 - Introduction/1.2 - Why Use the BurnySc2 Fork","docId":"Part 1 - Getting Started/Chapter 1 - Introduction/1.2 - Why Use the BurnySc2 Fork","unlisted":false},{"type":"link","label":"1.3 - What You Can Build","href":"/learn-python-sc2/docs/Part 1 - Getting Started/Chapter 1 - Introduction/1.3 - What You Can Build","docId":"Part 1 - Getting Started/Chapter 1 - Introduction/1.3 - What You Can Build","unlisted":false}]},{"type":"category","label":"Chapter 2 - Installation & First Bot","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"2.1 - Installing the Library","href":"/learn-python-sc2/docs/Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.1 - Installing the Library","docId":"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.1 - Installing the Library","unlisted":false},{"type":"link","label":"2.2 - Setting Up StarCraft II","href":"/learn-python-sc2/docs/Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.2 - Setting Up StarCraft II","docId":"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.2 - Setting Up StarCraft II","unlisted":false},{"type":"link","label":"2.3 - Running an Example Bot","href":"/learn-python-sc2/docs/Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.3 - Running an Example Bot","docId":"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.3 - Running an Example Bot","unlisted":false},{"type":"link","label":"2.4 - Your First Hello, World Bot","href":"/learn-python-sc2/docs/Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.4 - Your First Hello, World Bot","docId":"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.4 - Your First Hello, World Bot","unlisted":false}]}]},{"type":"category","label":"Part 2 - Core Concepts","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Chapter 3 - The BotAI Class","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"3.1 - The Heart of Your Bot","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.1 - The Heart of Your Bot","docId":"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.1 - The Heart of Your Bot","unlisted":false},{"type":"link","label":"3.2 - The Game Loop","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.2 - The Game Loop","docId":"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.2 - The Game Loop","unlisted":false},{"type":"link","label":"3.3 - The Power of Async and Await","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.3 - The Power of Async and Await","docId":"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.3 - The Power of Async and Await","unlisted":false}]},{"type":"category","label":"Chapter 4 - Reading the Game State","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"4.1 - Static Info - Map Name, Size, and Start Locations","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.1 - Static Info - Map Name, Size, and Start Locations","docId":"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.1 - Static Info - Map Name, Size, and Start Locations","unlisted":false},{"type":"link","label":"4.2 - Dynamic Info- Minerals, Supply, and Time","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.2 - Dynamic Info- Minerals, Supply, and Time","docId":"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.2 - Dynamic Info- Minerals, Supply, and Time","unlisted":false},{"type":"link","label":"4.3 - Understanding Units - The Unit Attributes","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.3 - Understanding Units - The Unit Attributes","docId":"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.3 - Understanding Units - The Unit Attributes","unlisted":false},{"type":"link","label":"4.4 - Managing Groups- The Units Collection","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.4 - Managing Groups- The Units Collection","docId":"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.4 - Managing Groups- The Units Collection","unlisted":false}]},{"type":"category","label":"Chapter 5 - Issuing Commands - Actions","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"5.1 - The Core of Control","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.1 - The Core of Control","docId":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.1 - The Core of Control","unlisted":false},{"type":"link","label":"5.2 - Basic Commands","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.2 - Basic Commands","docId":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.2 - Basic Commands","unlisted":false},{"type":"link","label":"5.3 - Worker Commands- Gather and Build","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.3 - Worker Commands- Gather and Build","docId":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.3 - Worker Commands- Gather and Build","unlisted":false},{"type":"link","label":"5.4 - Production- Training Units and Researching Upgrades","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.4 - Production- Training Units and Researching Upgrades","docId":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.4 - Production- Training Units and Researching Upgrades","unlisted":false},{"type":"link","label":"5.5 - Using Special Abilities","href":"/learn-python-sc2/docs/Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.5 - Using Special Abilities","docId":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.5 - Using Special Abilities","unlisted":false}]}]},{"type":"category","label":"Part 3 - Advanced Development","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Chapter 6 - Building a Smarter Bot","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"6.1 - Macro-management - Expanding and Managing Your Economy","href":"/learn-python-sc2/docs/Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.1 - Macro-management - Expanding and Managing Your Economy","docId":"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.1 - Macro-management - Expanding and Managing Your Economy","unlisted":false},{"type":"link","label":"6.2 - Micro-management - Controlling Units in Combat","href":"/learn-python-sc2/docs/Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.2 - Micro-management - Controlling Units in Combat","docId":"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.2 - Micro-management - Controlling Units in Combat","unlisted":false},{"type":"link","label":"6.3 - Querying the Game - Checking for Pathing and Abilities","href":"/learn-python-sc2/docs/Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.3 - Querying the Game - Checking for Pathing and Abilities","docId":"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.3 - Querying the Game - Checking for Pathing and Abilities","unlisted":false}]},{"type":"category","label":"Chapter 7 - Performance and Debugging","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"7.1 - Writing Efficient Code - Managing APM","href":"/learn-python-sc2/docs/Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.1 - Writing Efficient Code - Managing APM","docId":"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.1 - Writing Efficient Code - Managing APM","unlisted":false},{"type":"link","label":"7.2 - Common Pitfalls- Desyncs and Stale Data","href":"/learn-python-sc2/docs/Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.2 - Common Pitfalls- Desyncs and Stale Data","docId":"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.2 - Common Pitfalls- Desyncs and Stale Data","unlisted":false},{"type":"link","label":"7.3 - How to Debug and Analyze Replays","href":"/learn-python-sc2/docs/Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.3 - How to Debug and Analyze Replays","docId":"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.3 - How to Debug and Analyze Replays","unlisted":false},{"type":"link","label":"7.4 - Saving Data Between Matches","href":"/learn-python-sc2/docs/Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.4 - Saving Data Between Matches","docId":"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.4 - Saving Data Between Matches","unlisted":false}]}]},{"type":"category","label":"Part 4 - The Wider World","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Chapter 8 - Bot Vision - Advantages and Limitations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"8.1 - What Your Bot Sees That a Human Can\'t - API Advantages","href":"/learn-python-sc2/docs/Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.1 - What Your Bot Sees That a Human Can\'t - API Advantages","docId":"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.1 - What Your Bot Sees That a Human Can\'t - API Advantages","unlisted":false},{"type":"link","label":"8.2 - What Your Bot Can\'t See - API Limitations","href":"/learn-python-sc2/docs/Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.2 - What Your Bot Can\'t See - API Limitations","docId":"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.2 - What Your Bot Can\'t See - API Limitations","unlisted":false},{"type":"link","label":"8.3 - Optional - Using the Raw API","href":"/learn-python-sc2/docs/Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.3 - Optional - Using the Raw API","docId":"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.3 - Optional - Using the Raw API","unlisted":false}]},{"type":"category","label":"Chapter 9 - Community and Resources","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"9.1 - Where to Get Help - Discord & GitHub","href":"/learn-python-sc2/docs/Part 4 - The Wider World/Chapter 9 - Community and Resources/9.1 - Where to Get Help - Discord & GitHub","docId":"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.1 - Where to Get Help - Discord & GitHub","unlisted":false},{"type":"link","label":"9.2 - Competing with Your Bot - Ladders and Tournaments","href":"/learn-python-sc2/docs/Part 4 - The Wider World/Chapter 9 - Community and Resources/9.2 - Competing with Your Bot - Ladders and Tournaments","docId":"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.2 - Competing with Your Bot - Ladders and Tournaments","unlisted":false},{"type":"link","label":"9.3 - Learning From Other Bots","href":"/learn-python-sc2/docs/Part 4 - The Wider World/Chapter 9 - Community and Resources/9.3 - Learning From Other Bots","docId":"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.3 - Learning From Other Bots","unlisted":false}]}]},{"type":"category","label":"Part 5 - Reinforcement Learning","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Foundations of Reinforcement Learning","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Chapter 1 - Introduction to RL Concepts","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"1.1 - What is RL for SC2","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.1 - What is RL for SC2","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.1 - What is RL for SC2","unlisted":false},{"type":"link","label":"1.2 - The Core Challenge - async vs sync","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.2 - The Core Challenge - async vs sync","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.2 - The Core Challenge - async vs sync","unlisted":false},{"type":"link","label":"1.3 - Our Solution - The Gym Environment Wrapper","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.3 - Our Solution - The Gym Environment Wrapper","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.3 - Our Solution - The Gym Environment Wrapper","unlisted":false}]},{"type":"category","label":"Chapter 2 - Setting Up the RL Environment","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"2.1 - Installing RL Libraries","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 2 - Setting Up the RL Environment/2.1 - Installing RL Libraries","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 2 - Setting Up the RL Environment/2.1 - Installing RL Libraries","unlisted":false},{"type":"link","label":"2.2 - Code - The Reusable SC2GymEnv Wrapper","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 2 - Setting Up the RL Environment/2.2 - Code - The Reusable SC2GymEnv Wrapper","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 2 - Setting Up the RL Environment/2.2 - Code - The Reusable SC2GymEnv Wrapper","unlisted":false}]},{"type":"category","label":"Chapter 3 - The Worker Bot","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"3.1 - Goal - Learning a Single Economic Task","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.1 - Goal - Learning a Single Economic Task","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.1 - Goal - Learning a Single Economic Task","unlisted":false},{"type":"link","label":"3.2 - Design - Observation, Action, and Reward","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.2 - Design - Observation, Action, and Reward","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.2 - Design - Observation, Action, and Reward","unlisted":false},{"type":"link","label":"3.3 - Code - The Worker Bot Environment","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.3 - Code - The Worker Bot Environment","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.3 - Code - The Worker Bot Environment","unlisted":false}]},{"type":"category","label":"Chapter 4 - The Macro Bot","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"4.1 - Goal - Learning an Economic Trade-off","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off","unlisted":false},{"type":"link","label":"4.2 - Design - Expanding the State and Action Space","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space","unlisted":false},{"type":"link","label":"4.3 - Code - The Macro Bot Environment","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.3 - Code - The Macro Bot Environment","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.3 - Code - The Macro Bot Environment","unlisted":false}]},{"type":"category","label":"Chapter 5 - The Micro Bot","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"5.1 - Goal - Learning a Combat Skill - Kiting","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.1 - Goal - Learning a Combat Skill - Kiting","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.1 - Goal - Learning a Combat Skill - Kiting","unlisted":false},{"type":"link","label":"5.2 - Design - Observations for Spatial Awareness","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.2 - Design - Observations for Spatial Awareness","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.2 - Design - Observations for Spatial Awareness","unlisted":false},{"type":"link","label":"5.3 - Code - The Micro Bot Environment","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.3 - Code - The Micro Bot Environment","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.3 - Code - The Micro Bot Environment","unlisted":false}]},{"type":"category","label":"Chapter 6 - Training Your Agents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"6.1 - Code - The Reusable train.py Script","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.1 - Code - The Reusable train.py Script","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.1 - Code - The Reusable train.py Script","unlisted":false},{"type":"link","label":"6.2 - A Quick Look at the PPO Algorithm","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.2 - A Quick Look at the PPO Algorithm","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.2 - A Quick Look at the PPO Algorithm","unlisted":false},{"type":"link","label":"6.3 - Loading and Running a Trained Agent","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.3 - Loading and Running a Trained Agent","docId":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.3 - Loading and Running a Trained Agent","unlisted":false}]}]},{"type":"category","label":"Advanced RL and Next Steps","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Chapter 7 - Visualizing and Evaluating Training","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"7.1 - Setting up TensorBoard","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 7 - Visualizing and Evaluating Training/7.1 - Setting up TensorBoard","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 7 - Visualizing and Evaluating Training/7.1 - Setting up TensorBoard","unlisted":false},{"type":"link","label":"7.2 - What to Look For in Training Graphs","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 7 - Visualizing and Evaluating Training/7.2 - What to Look For in Training Graphs","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 7 - Visualizing and Evaluating Training/7.2 - What to Look For in Training Graphs","unlisted":false}]},{"type":"category","label":"Chapter 8 - Advanced Implementation - DRL-RM","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"8.1 - Concept - A More Generalized Agent","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.1 - Concept - A More Generalized Agent","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.1 - Concept - A More Generalized Agent","unlisted":false},{"type":"link","label":"8.2 - Code - A Simplified DRL-RM Implementation","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.2 - Code - A Simplified DRL-RM Implementation","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.2 - Code - A Simplified DRL-RM Implementation","unlisted":false},{"type":"link","label":"8.3 - The Challenge of a Large Action Space","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.3 - The Challenge of a Large Action Space","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.3 - The Challenge of a Large Action Space","unlisted":false}]},{"type":"category","label":"Chapter 9 - Improving Your Agent with Action Masking","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"9.1 - The Problem - Wasted, Impossible Actions","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.1 - The Problem - Wasted, Impossible Actions","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.1 - The Problem - Wasted, Impossible Actions","unlisted":false},{"type":"link","label":"9.2 - How Action Masking Works","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.2 - How Action Masking Works","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.2 - How Action Masking Works","unlisted":false},{"type":"link","label":"9.3 - Code - Implementing an Action Mask","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.3 - Code - Implementing an Action Mask","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.3 - Code - Implementing an Action Mask","unlisted":false}]},{"type":"category","label":"Chapter 10 - Improving Your Agent with Curriculum Learning","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"10.1 - The Concept - From Simple to Complex Tasks","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.1 - The Concept - From Simple to Complex Tasks","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.1 - The Concept - From Simple to Complex Tasks","unlisted":false},{"type":"link","label":"10.2 - Example - A Curriculum for the Micro Bot","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.2 - Example - A Curriculum for the Micro Bot","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.2 - Example - A Curriculum for the Micro Bot","unlisted":false}]},{"type":"category","label":"Chapter 11 - Conclusion and Further Exploration","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"11.1 - Summary of Your RL Journey","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.1 - Summary of Your RL Journey","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.1 - Summary of Your RL Journey","unlisted":false},{"type":"link","label":"11.2 - Advanced Concepts to Explore - HRL, MARL","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.2 - Advanced Concepts to Explore - HRL, MARL","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.2 - Advanced Concepts to Explore - HRL, MARL","unlisted":false},{"type":"link","label":"11.3 - Joining the Research Community","href":"/learn-python-sc2/docs/Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.3 - Joining the Research Community","docId":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.3 - Joining the Research Community","unlisted":false}]}]}]}]},"docs":{"Part 1 - Getting Started/Chapter 1 - Introduction/1.1 - What is python-sc2":{"id":"Part 1 - Getting Started/Chapter 1 - Introduction/1.1 - What is python-sc2","title":"1.1 - What is python-sc2","description":"python-sc2 is a Python library that enables you to program an artificial intelligence (AI) to play the real-time strategy game StarCraft II. It serves as a high-level, easy-to-use wrapper around Blizzard\'s official StarCraft II Machine Learning API.","sidebar":"tutorialSidebar"},"Part 1 - Getting Started/Chapter 1 - Introduction/1.2 - Why Use the BurnySc2 Fork":{"id":"Part 1 - Getting Started/Chapter 1 - Introduction/1.2 - Why Use the BurnySc2 Fork","title":"1.2 - Why Use the BurnySc2 Fork","description":"For any developer entering the StarCraft II AI scene today, the choice of library is simple: BurnySc2/python-sc2 is the only actively maintained and community-supported option. The original Dentosal/python-sc2 library should be considered archived and is unsuitable for new projects.","sidebar":"tutorialSidebar"},"Part 1 - Getting Started/Chapter 1 - Introduction/1.3 - What You Can Build":{"id":"Part 1 - Getting Started/Chapter 1 - Introduction/1.3 - What You Can Build","title":"1.3 - What You Can Build","description":"Using BurnySc2/python-sc2 is like being handed a key to one of the most complex real-time strategy environments ever created. Your code becomes the brain of a player, and the possibilities extend far beyond just \\"making a bot.\\"","sidebar":"tutorialSidebar"},"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.1 - Installing the Library":{"id":"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.1 - Installing the Library","title":"2.1 - Installing the Library","description":"This chapter will guide you through setting up your development environment and installing the burnysc2 library. Following these steps will ensure you have a clean, isolated, and verifiable setup, which is the professional standard for any software project.","sidebar":"tutorialSidebar"},"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.2 - Setting Up StarCraft II":{"id":"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.2 - Setting Up StarCraft II","title":"2.2 - Setting Up StarCraft II","description":"2.2. Setting Up the Game Environment","sidebar":"tutorialSidebar"},"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.3 - Running an Example Bot":{"id":"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.3 - Running an Example Bot","title":"2.3 - Running an Example Bot","description":"Now that your environment is configured, it\'s time for a \\"smoke test\\"\u2014running a simple, pre-written bot to confirm that all the pieces connect and function correctly. The goal here is not to understand every line of code, but to verify your setup.","sidebar":"tutorialSidebar"},"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.4 - Your First Hello, World Bot":{"id":"Part 1 - Getting Started/Chapter 2 - Installation & First Bot/2.4 - Your First Hello, World Bot","title":"2.4 - Your First Hello, World Bot","description":"In programming, a \\"Hello, World!\\" application is the simplest possible program that proves a new system is working. Our goal here is the same: we will build a bot that does nothing in-game but prints messages to your console.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.1 - The Heart of Your Bot":{"id":"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.1 - The Heart of Your Bot","title":"3.1 - The Heart of Your Bot","description":"At the center of every project is your main bot class. This class is not just a container for code; it\'s the brain of your entire operation. To write effective bots, you must first understand the structure of this class and the powerful \\"API contract\\" it fulfills by inheriting from the library\'s BotAI.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.2 - The Game Loop":{"id":"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.2 - The Game Loop","title":"3.2 - The Game Loop","description":"Your bot\'s code does not run all at once. It\'s an event-driven program that reacts to the game\'s state. The BotAI class provides a \\"three-act structure\\" for your bot\'s life within a match, giving you specific entry points to insert your logic. Understanding this flow is essential for building a well-structured AI.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.3 - The Power of Async and Await":{"id":"Part 2 - Core Concepts/Chapter 3 - The BotAI Class/3.3 - The Power of Async and Await","title":"3.3 - The Power of Async and Await","description":"The async and await keywords are the engine of python-sc2. They are not optional features; they are the fundamental mechanism that allows your bot to remain responsive and intelligent. Understanding their purpose is non-negotiable for writing a functional bot.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.1 - Static Info - Map Name, Size, and Start Locations":{"id":"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.1 - Static Info - Map Name, Size, and Start Locations","title":"4.1 - Static Info - Map Name, Size, and Start Locations","description":"Before a single unit moves, your bot needs a complete understanding of the environment. The self.game_info object is your access to this static blueprint. Think of it as the unchangeable physical game board: the map\'s size, terrain, and starting positions are all fixed at the beginning of the match and will not change.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.2 - Dynamic Info- Minerals, Supply, and Time":{"id":"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.2 - Dynamic Info- Minerals, Supply, and Time","title":"4.2 - Dynamic Info- Minerals, Supply, and Time","description":"If self.game_info is the unchanging blueprint of the battlefield, then the data available through self.state and its convenience properties represents your bot\'s real-time senses. This is the dynamic information\u2014minerals, supply, unit positions, time\u2014that changes on every single frame of the game.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.3 - Understanding Units - The Unit Attributes":{"id":"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.3 - Understanding Units - The Unit Attributes","title":"4.3 - Understanding Units - The Unit Attributes","description":"Every single entity on the battlefield\u2014from a Marine to a mineral patch, from a Pylon to a flying Overlord\u2014is represented in your code as a Unit object. This is the most fundamental data structure in python-sc2. It is both a data container and an actor: it holds all the information about an entity, and it is the object you use to issue it commands.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.4 - Managing Groups- The Units Collection":{"id":"Part 2 - Core Concepts/Chapter 4 - Reading the Game State/4.4 - Managing Groups- The Units Collection","title":"4.4 - Managing Groups- The Units Collection","description":"A single Unit is an atom, but StarCraft II is a game of armies. To manage groups of units\u2014your entire worker line, your main army, or an enemy attack wave\u2014you need a more powerful tool. The Units object is that tool.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.1 - The Core of Control":{"id":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.1 - The Core of Control","title":"5.1 - The Core of Control","description":"To issue actions effectively in python-sc2, it is essential to understand that there are two distinct architectural pathways for interacting with the StarCraft II engine, each optimized for a different purpose: Commands and Queries.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.2 - Basic Commands":{"id":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.2 - Basic Commands","title":"5.2 - Basic Commands","description":"Attack, Move, Stop, Hold Position","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.3 - Worker Commands- Gather and Build":{"id":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.3 - Worker Commands- Gather and Build","title":"5.3 - Worker Commands- Gather and Build","description":"Worker units are the engine of your economy and the architects of your base. They have two primary, specialized commands: gather for harvesting resources and build for constructing structures. While gathering is a simple \\"fire-and-forget\\" command, building requires a more deliberate, multi-step process.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.4 - Production- Training Units and Researching Upgrades":{"id":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.4 - Production- Training Units and Researching Upgrades","title":"5.4 - Production- Training Units and Researching Upgrades","description":"Once your base includes production structures, your bot\'s focus shifts to converting resources into military power. The commands for training units (.train()) and researching upgrades (.research()) are simple Commands. They are non-blocking and should be called directly without await.","sidebar":"tutorialSidebar"},"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.5 - Using Special Abilities":{"id":"Part 2 - Core Concepts/Chapter 5 - Issuing Commands - Actions/5.5 - Using Special Abilities","title":"5.5 - Using Special Abilities","description":"Beyond basic commands, many units have powerful abilities that define high-level strategy\u2014a Sentry\'s Force Field, a Ghost\'s Snipe, or a Queen\'s Inject Larva. The library provides a direct and intuitive syntax for using these abilities by making the Unit object itself \\"callable.\\"","sidebar":"tutorialSidebar"},"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.1 - Macro-management - Expanding and Managing Your Economy":{"id":"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.1 - Macro-management - Expanding and Managing Your Economy","title":"6.1 - Macro-management - Expanding and Managing Your Economy","description":"Macro-management (\\"macro\\") is the art of economy. It is a high-level, strategic process focused on resource collection, base expansion, and infrastructure development. A bot with superior macro can often defeat a bot with superior unit control (\\"micro\\") simply by producing a larger, better-equipped army.","sidebar":"tutorialSidebar"},"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.2 - Micro-management - Controlling Units in Combat":{"id":"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.2 - Micro-management - Controlling Units in Combat","title":"6.2 - Micro-management - Controlling Units in Combat","description":"If macro-management is about building a bigger army, micro-management (\\"micro\\") is about making that army fight smarter. It is the fine-grained, real-time control of individual units in combat to maximize their value, minimize losses, and ultimately win battles against superior numbers.","sidebar":"tutorialSidebar"},"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.3 - Querying the Game - Checking for Pathing and Abilities":{"id":"Part 3 - Advanced Development/Chapter 6 - Building a Smarter Bot/6.3 - Querying the Game - Checking for Pathing and Abilities","title":"6.3 - Querying the Game - Checking for Pathing and Abilities","description":"Your bot\'s standard senses (self.state and its helpers) provide a snapshot of what is. But to make truly intelligent decisions, your bot needs to ask what could be. Can a unit get from A to B? Is an ability actually ready to use? Answering these questions requires querying the game engine for a specific calculation.","sidebar":"tutorialSidebar"},"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.1 - Writing Efficient Code - Managing APM":{"id":"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.1 - Writing Efficient Code - Managing APM","title":"7.1 - Writing Efficient Code - Managing APM","description":"As your bot\'s intelligence grows, so does the complexity of its code. Inefficient code is not just a matter of elegance; it can lead to critical performance issues, including game-losing lag and desync bugs. Writing efficient code is about making your bot both fast and stable.","sidebar":"tutorialSidebar"},"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.2 - Common Pitfalls- Desyncs and Stale Data":{"id":"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.2 - Common Pitfalls- Desyncs and Stale Data","title":"7.2 - Common Pitfalls- Desyncs and Stale Data","description":"Beyond simple syntax errors, bot development has its own class of insidious bugs. Two of the most common and difficult to diagnose are desyncs and errors caused by stale data. Understanding these pitfalls is essential for building a stable and reliable bot.","sidebar":"tutorialSidebar"},"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.3 - How to Debug and Analyze Replays":{"id":"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.3 - How to Debug and Analyze Replays","title":"7.3 - How to Debug and Analyze Replays","description":"A bot can have flawless code but a flawed strategy. Identifying these strategic bugs requires a different approach than traditional debugging. Your primary tools are controlled local testing, instrumented logging, and most importantly, systematic replay analysis.","sidebar":"tutorialSidebar"},"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.4 - Saving Data Between Matches":{"id":"Part 3 - Advanced Development/Chapter 7 - Performance and Debugging/7.4 - Saving Data Between Matches","title":"7.4 - Saving Data Between Matches","description":"For a bot to learn, adapt, and improve over time, it must have a memory. It needs a way to store information from one match and retrieve it in the next. This capability, known as persistence, is the foundation of any learning AI.","sidebar":"tutorialSidebar"},"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.1 - What Your Bot Sees That a Human Can\'t - API Advantages":{"id":"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.1 - What Your Bot Sees That a Human Can\'t - API Advantages","title":"8.1 - What Your Bot Sees That a Human Can\'t - API Advantages","description":"Your bot is not a human. It \\"sees\\" the game through a direct data feed from the StarCraft II API, giving it several inherent perceptual advantages. These are not cheats; they are natural consequences of the API\'s design. Understanding these advantages is crucial because it frees you from writing complex code to simulate abilities your bot already has.","sidebar":"tutorialSidebar"},"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.2 - What Your Bot Can\'t See - API Limitations":{"id":"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.2 - What Your Bot Can\'t See - API Limitations","title":"8.2 - What Your Bot Can\'t See - API Limitations","description":"8.2. The Fog of Ignorance: API Limitations","sidebar":"tutorialSidebar"},"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.3 - Optional - Using the Raw API":{"id":"Part 4 - The Wider World/Chapter 8 - Bot Vision - Advantages and Limitations/8.3 - Optional - Using the Raw API","title":"8.3 - Optional - Using the Raw API","description":"The python-sc2 library is an abstraction layer. It acts as a sophisticated translator, converting the complex, raw data stream from the StarCraft II engine into clean, easy-to-use Python objects like Unit and Units. For 99% of developers, this high-level interface is the best and most productive way to build a bot.","sidebar":"tutorialSidebar"},"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.1 - Where to Get Help - Discord & GitHub":{"id":"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.1 - Where to Get Help - Discord & GitHub","title":"9.1 - Where to Get Help - Discord & GitHub","description":"No developer works in a vacuum. Bot development is a challenging field, and leveraging the collective knowledge of the community is essential for success. The two pillars of the python-sc2 community are the Discord server for real-time discussion and the GitHub repository for technical issues and source code.","sidebar":"tutorialSidebar"},"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.2 - Competing with Your Bot - Ladders and Tournaments":{"id":"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.2 - Competing with Your Bot - Ladders and Tournaments","title":"9.2 - Competing with Your Bot - Ladders and Tournaments","description":"9.2. Competing with Your Bot: Ladders and Tournaments","sidebar":"tutorialSidebar"},"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.3 - Learning From Other Bots":{"id":"Part 4 - The Wider World/Chapter 9 - Community and Resources/9.3 - Learning From Other Bots","title":"9.3 - Learning From Other Bots","description":"9.3. Learning From Other Bots","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.1 - The Concept - From Simple to Complex Tasks":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.1 - The Concept - From Simple to Complex Tasks","title":"10.1 - The Concept - From Simple to Complex Tasks","description":"A significant challenge in reinforcement learning is that training an agent on a complex, final task from a random starting point can be extraordinarily inefficient or even impossible. The agent often fails to discover the rare, early-stage actions that lead to long-term success.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.2 - Example - A Curriculum for the Micro Bot":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 10 - Improving Your Agent with Curriculum Learning/10.2 - Example - A Curriculum for the Micro Bot","title":"10.2 - Example - A Curriculum for the Micro Bot","description":"Let\'s apply the theory of Curriculum Learning to a practical example. We will design a simple, three-stage curriculum to teach our MicroBot agent how to handle progressively more complex combat scenarios.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.1 - Summary of Your RL Journey":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.1 - Summary of Your RL Journey","title":"11.1 - Summary of Your RL Journey","description":"This chapter concludes our guide to applying reinforcement learning to StarCraft II. Over the preceding sections, you have progressed from the foundational theory to the practical implementation of multiple learning agents, culminating in advanced training strategies.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.2 - Advanced Concepts to Explore - HRL, MARL":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.2 - Advanced Concepts to Explore - HRL, MARL","title":"11.2 - Advanced Concepts to Explore - HRL, MARL","description":"The monolithic, single-agent architectures we have implemented are powerful but have inherent limitations in solving problems that require both long-term strategy and fine-grained, parallel control. To address this, the field of reinforcement learning offers more advanced architectural paradigms.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.3 - Joining the Research Community":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 11 - Conclusion and Further Exploration/11.3 - Joining the Research Community","title":"11.3 - Joining the Research Community","description":"Having progressed through this documentation, you have moved beyond being a user of python-sc2 to become a practitioner of StarCraft II AI. The final and most rewarding step in this journey is to evolve from a practitioner into a contributor.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 7 - Visualizing and Evaluating Training/7.1 - Setting up TensorBoard":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 7 - Visualizing and Evaluating Training/7.1 - Setting up TensorBoard","title":"7.1 - Setting up TensorBoard","description":"Training a reinforcement learning agent is an empirical process. To understand if the agent is learning, improving, or stagnating, you must visualize its performance metrics over time. TensorBoard is the industry-standard tool for this purpose.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 7 - Visualizing and Evaluating Training/7.2 - What to Look For in Training Graphs":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 7 - Visualizing and Evaluating Training/7.2 - What to Look For in Training Graphs","title":"7.2 - What to Look For in Training Graphs","description":"TensorBoard provides a rich suite of metrics, but effective diagnostics requires focusing on a few key indicators. These graphs tell a story about the health and progress of your agent\'s learning process. By learning to interpret their patterns, you can quickly diagnose issues with your environment design or hyperparameter tuning.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.1 - Concept - A More Generalized Agent":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.1 - Concept - A More Generalized Agent","title":"8.1 - Concept - A More Generalized Agent","description":"The agents developed in Part 5, while effective at their specific tasks, are fundamentally limited by their fixed-size observation and action spaces. They are brittle; the MicroBot has no capacity to handle a second Zergling, and the MacroBot has no concept of building a Barracks.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.2 - Code - A Simplified DRL-RM Implementation":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.2 - Code - A Simplified DRL-RM Implementation","title":"8.2 - Code - A Simplified DRL-RM Implementation","description":"This file provides a functional, albeit simplified, implementation of the \\"generalized agent\\" concept. It is designed to handle a variable number of units by encoding the game state into an entity list and using a decomposed action space.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.3 - The Challenge of a Large Action Space":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 8 - Advanced Implementation - DRL-RM/8.3 - The Challenge of a Large Action Space","title":"8.3 - The Challenge of a Large Action Space","description":"The architectural shift to a generalized, entity-based agent provides immense flexibility but introduces a significant and well-known challenge in reinforcement learning: the combinatorial explosion of the action space.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.1 - The Problem - Wasted, Impossible Actions":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.1 - The Problem - Wasted, Impossible Actions","title":"9.1 - The Problem - Wasted, Impossible Actions","description":"The shift to a generalized, decomposed action space in our DRLRMBot architecture, while powerful, introduces a well-known and critical challenge in applied reinforcement learning: the Invalid Action Problem. The agent\'s theoretical action space becomes vastly larger than its effective action space at any given moment, which severely impedes the learning process.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.2 - How Action Masking Works":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.2 - How Action Masking Works","title":"9.2 - How Action Masking Works","description":"Action Masking is an architectural pattern that solves the Invalid Action Problem by injecting domain knowledge directly into the agent\'s decision-making process. Instead of letting the agent explore the entire theoretical action space, the environment provides a \\"mask\\" on each step that restricts the agent\'s choices to only those that are currently valid.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.3 - Code - Implementing an Action Mask":{"id":"Part 5 - Reinforcement Learning/Advanced RL and Next Steps/Chapter 9 - Improving Your Agent with Action Masking/9.3 - Code - Implementing an Action Mask","title":"9.3 - Code - Implementing an Action Mask","description":"This section provides the complete, updated code required to implement action masking in our DRLRMBot environment. This is a critical upgrade that makes training the generalized agent feasible by focusing its exploration on valid actions only.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.1 - What is RL for SC2":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.1 - What is RL for SC2","title":"1.1 - What is RL for SC2","description":"The documentation so far has focused on building scripted agents. In that paradigm, you, the developer, explicitly write the rules (if/then/else logic) that determine the bot\'s behavior. Reinforcement Learning (RL) introduces a fundamentally different approach: instead of writing the rules, you define a goal, and the agent learns its own rules through trial and error.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.2 - The Core Challenge - async vs sync":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.2 - The Core Challenge - async vs sync","title":"1.2 - The Core Challenge - async vs sync","description":"The primary technical hurdle in integrating python-sc2 with a library like stable-baselines3 is not specific to StarCraft II, but is a fundamental architectural conflict between their programming models: one is asynchronous and the other is synchronous.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.3 - Our Solution - The Gym Environment Wrapper":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 1 - Introduction to RL Concepts/1.3 - Our Solution - The Gym Environment Wrapper","title":"1.3 - Our Solution - The Gym Environment Wrapper","description":"To resolve the async vs. sync conflict, we will architect a solution using a well-established software design pattern: an Adapter. We will create a custom Python class that acts as a bridge, presenting a standard, synchronous gymnasium interface to the RL agent, while internally managing the complex, asynchronous python-sc2 game process.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 2 - Setting Up the RL Environment/2.1 - Installing RL Libraries":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 2 - Setting Up the RL Environment/2.1 - Installing RL Libraries","title":"2.1 - Installing RL Libraries","description":"Key Changes: This revision elevates the documentation from a simple list of commands to a professional setup guide. It introduces a \\"Project Dependencies\\" table to clearly define the role of each library, providing essential context for a developer. The installation process is framed as a formal \\"Setup Workflow\\" checklist, and a crucial note about PyTorch as the deep learning backend has been added. The verification step is also made more robust by including the library versions, which is a standard practice for ensuring a reproducible environment.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 2 - Setting Up the RL Environment/2.2 - Code - The Reusable SC2GymEnv Wrapper":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 2 - Setting Up the RL Environment/2.2 - Code - The Reusable SC2GymEnv Wrapper","title":"2.2 - Code - The Reusable SC2GymEnv Wrapper","description":"This file provides the complete, reusable implementation of the SC2GymEnv class. This class is the architectural cornerstone of our project, acting as the adapter that allows the synchronous stable-baselines3 library to communicate with the asynchronous python-sc2 game engine.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.1 - Goal - Learning a Single Economic Task":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.1 - Goal - Learning a Single Economic Task","title":"3.1 - Goal - Learning a Single Economic Task","description":"Our first foray into reinforcement learning will be a foundational \\"Hello, World!\\" task. The objective is to create the simplest possible environment where an agent can learn a single, vital economic behavior: producing worker units.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.2 - Design - Observation, Action, and Reward":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.2 - Design - Observation, Action, and Reward","title":"3.2 - Design - Observation, Action, and Reward","description":"The performance and success of a reinforcement learning agent are dictated by the quality of its environment design. This document serves as the formal design specification for the three core components of our WorkerEnv: the Observation Space, the Action Space, and the Reward Function.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.3 - Code - The Worker Bot Environment":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 3 - The Worker Bot/3.3 - Code - The Worker Bot Environment","title":"3.3 - Code - The Worker Bot Environment","description":"This file provides the complete implementation for our first reinforcement learning task. It contains two key classes: WorkerBot, the BotAI that executes within the game, and WorkerEnv, the gymnasium.Env that provides the interface to the stable-baselines3 agent.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.1 - Goal - Learning an Economic Trade-off","title":"4.1 - Goal - Learning an Economic Trade-off","description":"Having successfully trained an agent on a single task, we now introduce a core element of strategy games: decision-making under constraints. Our second agent will learn to manage the fundamental economic trade-off between building more workers (increasing income) and building more supply (increasing capacity).","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.2 - Design - Expanding the State and Action Space","title":"4.2 - Design - Expanding the State and Action Space","description":"To graduate our agent from a single-purpose actor to a decision-maker, we must evolve its environment. This involves expanding its \\"senses\\" (the observation space) and its \\"abilities\\" (the action space) to provide the necessary tools for learning the more complex task of balancing economic priorities.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.3 - Code - The Macro Bot Environment":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 4 - The Macro Bot/4.3 - Code - The Macro Bot Environment","title":"4.3 - Code - The Macro Bot Environment","description":"This file contains the complete implementation of the MacroEnv. It builds directly upon the concepts from the WorkerBot but expands the agent\'s capabilities to include managing supply, forcing it to learn a more complex economic policy.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.1 - Goal - Learning a Combat Skill - Kiting":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.1 - Goal - Learning a Combat Skill - Kiting","title":"5.1 - Goal - Learning a Combat Skill - Kiting","description":"This chapter marks a transition from macroeconomic tasks to micro-management. Our third agent will be trained to master a fundamental combat tactic known as kiting or \\"stutter-stepping.\\"","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.2 - Design - Observations for Spatial Awareness":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.2 - Design - Observations for Spatial Awareness","title":"5.2 - Design - Observations for Spatial Awareness","description":"To transition from abstract economic management to concrete combat micro-management, we must fundamentally redesign our agent\'s perception. The observation space must now encode spatial and temporal relationships between units on the battlefield.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.3 - Code - The Micro Bot Environment":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 5 - The Micro Bot/5.3 - Code - The Micro Bot Environment","title":"5.3 - Code - The Micro Bot Environment","description":"This file, micro_bot.py, provides the complete implementation for our combat micro-management task. It defines the MicroBot and MicroEnv classes, which create a controlled 1v1 kiting scenario for our agent to learn in.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.1 - Code - The Reusable train.py Script":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.1 - Code - The Reusable train.py Script","title":"6.1 - Code - The Reusable train.py Script","description":"This train.py script serves as the main entry point for our entire reinforcement learning application. It is the top-level, synchronous process that orchestrates the creation of the learning environment, the training of the agent, and the saving of the final model.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.2 - A Quick Look at the PPO Algorithm":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.2 - A Quick Look at the PPO Algorithm","title":"6.2 - A Quick Look at the PPO Algorithm","description":"Our training script utilizes Proximal Policy Optimization (PPO), a state-of-the-art reinforcement learning algorithm from the family of policy gradient methods. For the developer, PPO\'s primary appeal is its exceptional balance of sample efficiency, ease of implementation, and stability, making it a robust and reliable choice for a wide range of problems.","sidebar":"tutorialSidebar"},"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.3 - Loading and Running a Trained Agent":{"id":"Part 5 - Reinforcement Learning/Foundations of Reinforcement Learning/Chapter 6 - Training Your Agents/6.3 - Loading and Running a Trained Agent","title":"6.3 - Loading and Running a Trained Agent","description":"Training a model is only half the process. Once you have a trained agent saved to a file, you need a way to load and run it for evaluation, a process known as inference. This allows you to watch your agent perform, test its capabilities against specific opponents, and verify its learned policy without the overhead of retraining.","sidebar":"tutorialSidebar"}}}}')}}]);